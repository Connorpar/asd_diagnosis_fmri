{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rs_fMRI_transfomer_pretraining_n.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMgyutiPbjMY"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, AveragePooling2D, AveragePooling1D\n",
        "from keras.metrics import BinaryAccuracy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cnE-Rp7cxo-"
      },
      "source": [
        "# X = np.load('ABIDE_X.npy', allow_pickle=True)\n",
        "# Y = np.load('ABIDE_Y.npy', allow_pickle=True)\n",
        "# X = np.load('total_X.npy', allow_pickle=True)\n",
        "# Y = np.load('total_Y.npy', allow_pickle=True)\n",
        "X = np.load('ABIDE_X.npy', allow_pickle=True)\n",
        "Y = np.load('ABIDE_Y.npy', allow_pickle=True)"
      ],
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mO-FDnc2iJE"
      },
      "source": [
        "vals = np.empty((0,))\n",
        "for s in X:\n",
        "  vals = np.append(vals, s.flatten())\n"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKogCXFH08lC",
        "outputId": "104be649-5dc4-4a46-c247-26007524feb6"
      },
      "source": [
        "roi_ss = StandardScaler()\n",
        "roi_ss.fit(vals.reshape(-1, 1))"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5G4uiUPhNA-"
      },
      "source": [
        "del vals"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOz3cB8vfYjX"
      },
      "source": [
        "# Since scans are 2s apart 90 scans is 3 mins\n",
        "L = 10\n",
        "# Number of clips per subject\n",
        "N=10\n",
        "# Number of ROIs\n",
        "N_rois = 200\n",
        "feat_name = 'filt_noglobal_roi_200_Cradd'\n",
        "def extract_feat_sections(data, L=L, N=N):\n",
        "    feat_secs = list()\n",
        "    for i in range(N):\n",
        "        r = int(random.random() * (len(data) - L))\n",
        "        feat_secs.append(data[r:r+L])\n",
        "    return np.array(feat_secs)\n",
        "\n",
        "def create_dataset(X_arr, Y_arr, L=L,N=N):\n",
        "    X = list()\n",
        "    Y = list()\n",
        "    for n, data in enumerate(X_arr):\n",
        "        feat_secs = extract_feat_sections(data)\n",
        "        X.extend(feat_secs)\n",
        "        for i in range(len(feat_secs)):\n",
        "            Y.append(Y_arr[n, 2])\n",
        "    assert len(X) == len(Y)\n",
        "    X_ar = np.array(X).reshape(len(X), L, N_rois)\n",
        "    Y_ar = np.array(Y)\n",
        "    return X_ar, Y_ar"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LPqrrLkIQdb"
      },
      "source": [
        "# Since scans are 2s apart 90 scans is 3 mins\n",
        "# L = 90\n",
        "L = 10\n",
        "# Number of clips per subject\n",
        "# N=10\n",
        "N = 10\n",
        "# Number of ROIs\n",
        "N_rois = 200\n",
        "# Number of ROIS to swap\n",
        "# N_swap_rois = int(L *.1)\n",
        "N_swap_rois = 2\n",
        "\n",
        "def swap_rois(feat_sec):\n",
        "  swapped_feat_sec = copy.deepcopy(feat_sec)\n",
        "  swap_indexes = set()\n",
        "  # select random indexes to swap\n",
        "  while len(swap_indexes) < N_swap_rois:\n",
        "    swap_indexes.add(random.randint(0,L-1))\n",
        "  swap_indexes_l = list(swap_indexes)\n",
        "  swap_indexes_l_2 = copy.deepcopy(swap_indexes_l)\n",
        "  # ensure no indexes are the same in two lists\n",
        "  same = True\n",
        "  while same:\n",
        "    same = False  \n",
        "    random.shuffle(swap_indexes_l)\n",
        "    for n, i in enumerate(swap_indexes_l):\n",
        "      dist = np.linalg.norm(feat_sec[i]-feat_sec[swap_indexes_l_2[n]])\n",
        "      if(dist == 0):\n",
        "        same = True\n",
        "  for n, i in enumerate(swap_indexes_l):\n",
        "    swapped_feat_sec[i] = feat_sec[n]\n",
        "  # generate swap label\n",
        "  swap_label = np.zeros((L, ))\n",
        "  for i in swap_indexes_l:\n",
        "    swap_label[i] = 1\n",
        "  # run again if didn't properly swap\n",
        "  good_swap = True\n",
        "  for i, roi in enumerate(feat_sec):\n",
        "    dist = np.linalg.norm(roi-swapped_feat_sec[i])\n",
        "    if dist > 0:\n",
        "      if i not in swap_indexes:\n",
        "        good_swap = False\n",
        "    else:\n",
        "      if i in swap_indexes:\n",
        "        good_swap = False\n",
        "  if good_swap:\n",
        "    return swapped_feat_sec, swap_label\n",
        "  else:\n",
        "    return swap_rois(feat_sec)\n",
        "\n",
        "def create_pretraining_dataset(X_arr, Y_arr, L=L,N=N):\n",
        "    X = list()\n",
        "    Y = list()\n",
        "    for n, data in enumerate(X_arr):\n",
        "        feat_secs = extract_feat_sections(data)\n",
        "        for feat_sec in feat_secs:\n",
        "          feat_sec_swapped, swap_label = swap_rois(feat_sec)\n",
        "          X.append(feat_sec_swapped)\n",
        "          Y.append(swap_label)\n",
        "    assert len(X) == len(Y)\n",
        "    X_ar = np.array(X).reshape(len(X), L, N_rois)\n",
        "    Y_ar = np.array(Y)\n",
        "    return X_ar, Y_ar"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6UGd4MoJqdr"
      },
      "source": [
        "# Since scans are 2s apart 90 scans is 3 mins\n",
        "L = 90\n",
        "# Number of clips per subject\n",
        "N=10\n",
        "# Number of ROIs\n",
        "N_rois = 200\n",
        "\n",
        "def create_pretraining_dataset_next_pred(X_arr, Y_arr, L=L,N=N):\n",
        "    X = list()\n",
        "    Y = list()\n",
        "    for n, data in enumerate(X_arr):\n",
        "        feat_secs = extract_feat_sections(data, L+1)\n",
        "        for feat_sec in feat_secs:\n",
        "          norm_feat_sec =  feat_sec[0:L] / np.linalg.norm(feat_sec[0:L])\n",
        "          # norm_feat_sec = feat_sec[0:L]\n",
        "          X.append(norm_feat_sec)\n",
        "          # norm_next = feat_sec[-1] / np.linalg.norm(feat_sec[-1])\n",
        "          next = feat_sec[-1]\n",
        "          Y.append(next)\n",
        "    assert len(X) == len(Y)\n",
        "    X_ar = np.array(X).reshape(len(X), L, N_rois)\n",
        "    Y_ar = np.array(Y)\n",
        "    return X_ar, Y_ar"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCq6RLuFCkkS"
      },
      "source": [
        "# Since scans are 2s apart 90 scans is 3 mins\n",
        "L = 90\n",
        "# Number of clips per subject\n",
        "N = int(10*90/L)\n",
        "# Number of ROIs\n",
        "N_rois = 200\n",
        "feat_name = 'filt_noglobal_roi_200_Cradd'\n",
        "\n",
        "def create_pretraining_dataset_total(X_arr, Y_arr, L=L,N=N, gender_even=False, roi_ss=None):\n",
        "    X = list()\n",
        "    Y_pred_n = list()\n",
        "    Y_gen = list()\n",
        "    Y_age = list()\n",
        "    Y_asd = list()\n",
        "    # calculate percentage of X_arr that is female\n",
        "    for n, data in enumerate(X_arr):\n",
        "        # Number of secs to pull proporational to length of data\n",
        "        N_secs = int(N*data.shape[0]/100)\n",
        "        feat_secs = extract_feat_sections(data, L+1, N_secs)\n",
        "        for feat_sec in feat_secs:\n",
        "          # norm_feat_sec =  feat_sec[0:L] / np.linalg.norm(feat_sec[0:L])\n",
        "          norm_feat_sec = roi_ss.transform(feat_sec[0:L])\n",
        "          X.append(norm_feat_sec)\n",
        "          # norm_next = feat_sec[-1] / np.linalg.norm(feat_sec[-1])\n",
        "          next = feat_sec[-1]\n",
        "          if roi_ss is not None:\n",
        "            # p_n = list()\n",
        "            # for n in next:\n",
        "            #   p_n.append(np.float32(n))\n",
        "            # next = roi_ss.transform(np.array(p_n).reshape(1, 200)) \n",
        "            next = roi_ss.transform(next.reshape(-1, 1)) \n",
        "          # Y.append(np.array([norm_next, Y_arr[n][0], Y_arr[n][1]]))\n",
        "          Y_pred_n.append(next)\n",
        "          Y_gen.append(int(Y_arr[n][0]))\n",
        "          Y_age.append([Y_arr[n][1]])\n",
        "          Y_asd.append(int(Y_arr[n][2]))\n",
        "    if gender_even:\n",
        "      p = Y_gen.count(0) / Y_gen.count(1)\n",
        "      X_even = list()\n",
        "      Y_pred_n_even = list()\n",
        "      Y_gen_even = list()\n",
        "      Y_age_even = list()\n",
        "      Y_asd_even = list()\n",
        "      for n, g in enumerate(Y_gen):\n",
        "        if g == 0:\n",
        "          X_even.append(X[n])\n",
        "          Y_pred_n_even.append(Y_pred_n[n])\n",
        "          Y_gen_even.append(0)\n",
        "          Y_age_even.append(Y_age[n])\n",
        "          Y_asd_even.append(Y_asd[n])\n",
        "        else:\n",
        "          r = random.random()\n",
        "          if r <= p:\n",
        "            X_even.append(X[n])\n",
        "            Y_pred_n_even.append(Y_pred_n[n])\n",
        "            Y_gen_even.append(1)\n",
        "            Y_age_even.append(Y_age[n])\n",
        "            Y_asd_even.append(Y_asd[n])\n",
        "      X = X_even\n",
        "      Y_pred_n = Y_pred_n_even\n",
        "      Y_gen = Y_gen_even\n",
        "      Y_age = Y_age_even\n",
        "      Y_asd = Y_asd_even\n",
        "\n",
        "    \n",
        "    assert len(X) == len(Y_pred_n) == len(Y_gen) == len(Y_age) == len(Y_asd)\n",
        "    X_ar = np.array(X).reshape(len(X), L, N_rois)\n",
        "    return X_ar, np.array(Y_pred_n), np.array(Y_gen), np.array(Y_age), np.array(Y_asd)"
      ],
      "execution_count": 439,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4xACX6KOKeI",
        "outputId": "e12a53cc-6368-4dbe-9ffe-16fa30d5295f"
      },
      "source": [
        "# To start will just randomly split subjects into groups\n",
        "random_seed = 46\n",
        "val_per = .1\n",
        "test_per = 0\n",
        "train_sub_X, val_sub_X, train_sub_Y, val_sub_Y = train_test_split(X, Y, test_size=val_per + test_per, random_state=random_seed)\n",
        "if(test_per > 0):\n",
        "  val_sub_X, test_sub_X, val_sub_Y, test_sub_Y= train_test_split(val_sub_X, val_sub_Y, test_size=test_per/(val_per + test_per), random_state=random_seed + 1)\n",
        "print(f'{len(train_sub_X)} subjects for training.')\n",
        "print(f'{len(val_sub_X)} subjects for validation')\n",
        "if(test_per > 0):\n",
        "  print(f'{len(test_sub_X)} subjects for testing')"
      ],
      "execution_count": 440,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "854 subjects for training.\n",
            "95 subjects for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqN98HTupgUw"
      },
      "source": [
        "# Save ram by deleting vars\n",
        "del X\n",
        "del Y"
      ],
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gxatFYMOMza",
        "outputId": "7efe9433-0b6f-4f34-dc10-9e74cac6cf63"
      },
      "source": [
        "# Randomly extracts 10 shorter clips from each subject\n",
        "# Generate pre-training swaps\n",
        "# train_X, train_Y = create_pretraining_dataset(train_sub_X, train_sub_Y)\n",
        "# val_X, val_Y = create_pretraining_dataset(val_sub_X, val_sub_Y)\n",
        "# test_X, test_Y = create_pretraining_dataset(test_sub_X, test_sub_Y)\n",
        "# train_X, train_Y = create_pretraining_dataset_next_pred(train_sub_X, train_sub_Y)\n",
        "# val_X, val_Y = create_pretraining_dataset_next_pred(val_sub_X, val_sub_Y)\n",
        "# test_X, test_Y = create_pretraining_dataset_next_pred(test_sub_X, test_sub_Y)\n",
        "train_X, train_Y_pred_n, train_Y_gen, train_Y_age, train_Y_asd = create_pretraining_dataset_total(train_sub_X, train_sub_Y, roi_ss=roi_ss)\n",
        "val_X, val_Y_pred_n, val_Y_gen, val_Y_age, val_Y_asd = create_pretraining_dataset_total(val_sub_X, val_sub_Y, roi_ss=roi_ss)\n",
        "if(test_per > 0):\n",
        "  test_X, test_Y_pred_n, test_Y_gen, test_Y_age = create_pretraining_dataset_total(test_sub_X, test_sub_Y, roi_ss=roi_ss)\n",
        "train_Y, val_Y, test_Y = None, None, None\n",
        "# train_X, train_Y = create_dataset(train_sub_X, train_sub_Y)\n",
        "# val_X, val_Y = create_dataset(val_sub_X, val_sub_Y)\n",
        "# test_X, test_Y = create_dataset(test_sub_X, test_sub_Y)\n",
        "print(f'{len(train_X)} training examples')\n",
        "print(f'{len(val_X)} validation examples')\n",
        "if(test_per > 0):\n",
        "  print(f'{len(test_X)} testing examples')"
      ],
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16130 training examples\n",
            "1722 validation examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vwamksQqOIY"
      },
      "source": [
        "# Save ram by deleting vars\n",
        "del train_sub_X\n",
        "del train_sub_Y\n",
        "del val_sub_X\n",
        "del val_sub_Y"
      ],
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKT_BuN3-S8g",
        "outputId": "0b34eba7-319a-4d72-c683-f2bb5a6313c7"
      },
      "source": [
        "list(train_Y_asd).count(0)"
      ],
      "execution_count": 417,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 417
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBPzHopU_EKt",
        "outputId": "d56e28b8-ac9a-4452-995b-f0b1c5a11f9e"
      },
      "source": [
        "list(train_Y_asd).count(1)"
      ],
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2412"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tewvx-g_oIOA"
      },
      "source": [
        "# age_ss = StandardScaler()\n",
        "# n_age_bins = 5\n",
        "# age_ss = KBinsDiscretizer(n_bins=n_age_bins, encode='ordinal', strategy='quantile')\n",
        "# train_Y_age = age_ss.fit_transform(train_Y_age)\n",
        "# val_Y_age = age_ss.transform(val_Y_age)\n",
        "# test_Y_age = age_ss.transform(test_Y_age)"
      ],
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Vp93RTV6tDQN",
        "outputId": "436a0846-5b9d-426c-c2a1-ee2ed8066f28"
      },
      "source": [
        "plt.hist(train_Y_age)"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.370e+03, 2.115e+03, 1.132e+03, 4.180e+02, 2.910e+02, 7.400e+01,\n",
              "        4.300e+01, 1.500e+01, 2.000e+00, 9.000e+00]),\n",
              " array([ 5.22 , 10.318, 15.416, 20.514, 25.612, 30.71 , 35.808, 40.906,\n",
              "        46.004, 51.102, 56.2  ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 380
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7k7oqJ_OXq_"
      },
      "source": [
        "Create Transfomer Model and pre-train on swapped rois task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8ZDlPblOcTX"
      },
      "source": [
        "# Add classifcation token to beginning of input\n",
        "# classifcation token is an array of 0's and will be the input to the downstream classification tasks\n",
        "def add_cls_token(X, Y, swap=True, N=1):\n",
        "  # cls_array = np.zeros((X.shape[0], N, N_rois))\n",
        "  cls_array = np.ones((X.shape[0], N, N_rois))\n",
        "  t_X = np.append(cls_array, X, 1)\n",
        "  X = t_X\n",
        "  if swap:\n",
        "    zeros_ar = np.zeros((Y.shape[0],))[...,None] # None needed to keep shape\n",
        "    t_Y = np.append(zeros_ar, Y, 1)\n",
        "  else:\n",
        "    t_Y = Y\n",
        "  return t_X, t_Y"
      ],
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWVuohG7Ol0w"
      },
      "source": [
        "swap = False\n",
        "N = 4 # Number of CLS tokens to add\n",
        "train_X_t, train_Y_t = add_cls_token(train_X, train_Y, swap, N) \n",
        "val_X_t, val_Y_t = add_cls_token(val_X, val_Y, swap, N)\n",
        "if(test_per > 0): \n",
        "  test_X_t, test_Y_t = add_cls_token(test_X, test_Y, swap, N) "
      ],
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h3Om0P9qhFv"
      },
      "source": [
        "del train_X, train_Y, val_X, val_Y"
      ],
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKeJnd20Ondf"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNODLFfBOrxs"
      },
      "source": [
        "class PositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, embed_dim):\n",
        "        super(PositionEmbedding, self).__init__()\n",
        "        self.maxlen = maxlen\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        positions = tf.range(start=0, limit=self.maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions"
      ],
      "execution_count": 446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaSEUfJXNllf"
      },
      "source": [
        "def precision(y_true, y_pred):\n",
        "  '''\n",
        "  tp/(tp + fp)\n",
        "  '''\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  return true_positives / (predicted_positives + K.epsilon())"
      ],
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJhqRj9zOlCB"
      },
      "source": [
        "def recall(y_true, y_pred): \n",
        "  '''\n",
        "  tp / (tp + fn)\n",
        "  '''\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  return true_positives / (possible_positives + K.epsilon())"
      ],
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtwlcAmMS_fr"
      },
      "source": [
        "def specificity(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    tn / (tn + fp)\n",
        "    \"\"\"\n",
        "    neg_y_true = 1 - y_true\n",
        "    neg_y_pred = 1 - y_pred\n",
        "    fp = K.sum(neg_y_true * y_pred)\n",
        "    tn = K.sum(neg_y_true * neg_y_pred)\n",
        "    specificity = tn / (tn + fp + K.epsilon())\n",
        "    return specificity"
      ],
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AY9OHerATkO"
      },
      "source": [
        "def f1_loss(y_true, y_pred):\n",
        "  tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "  tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "  fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "  fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "  p = tp / (tp + fp + K.epsilon())\n",
        "  r = tp / (tp + fn + K.epsilon())\n",
        "  s = tn / (tn + fp + K.epsilon())\n",
        "\n",
        "  f1 = 2*p*r / (p+r+K.epsilon())\n",
        "  f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "  # return 1 - K.mean(f1)\n",
        "  return 1 - p*p*r*r*s"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEOd7LZoTBe6"
      },
      "source": [
        "def vec_dist_loss(y_true, y_pred):\n",
        "  s = y_true - y_pred\n",
        "  output = K.sum(s ** 2,axis=1,keepdims=True)\n",
        "  y_true_val = K.sum(y_true **2, axis=1, keepdims=True)\n",
        "  return output "
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltsf82pwYV6M"
      },
      "source": [
        "# returns lr for first ten epochs and exponentially decreases after\n",
        "def lr_scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)"
      ],
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsLuCCfzXcXz"
      },
      "source": [
        "class callback(keras.callbacks.Callback):\n",
        "    def __init__(self, model, X_train):\n",
        "        self.model = model\n",
        "        self.x = X_train\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # inp = self.model.input  # input placeholder\n",
        "        inp = self.x\n",
        "        outputs = self.model.layers[0].output  # get output of N's layer\n",
        "        functors = K.function([inp, K.learning_phase()], [outputs])\n",
        "        layer_outs = functors([self.x, 1.])\n",
        "        print('\\r OUTPUT TENSOR : %s' % layer_outs)\n",
        "\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjY1HTH_Ot6n",
        "outputId": "e604f894-c4b8-4839-85e0-679d9a87793b"
      },
      "source": [
        "embed_dim = N_rois  # Embedding size for each token\n",
        "num_heads = 8  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "max_len = L + N\n",
        "dropout_rate = .5\n",
        "\n",
        "inputs = layers.Input(shape=(max_len, embed_dim))\n",
        "pos_embedding_layer = PositionEmbedding(max_len, embed_dim)\n",
        "x = pos_embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x1 = x[:, 0, :] # just use cls token\n",
        "x2 = x[:, 1, :] # just use cls token\n",
        "x3 = x[:, 2, :] # just use cls token\n",
        "x4 = x[:, 3, :]\n",
        "\n",
        "K.print_tensor(x1)\n",
        "\n",
        "# Next activation prediction\n",
        "x1 = layers.Dropout(dropout_rate )(x1)\n",
        "x1 = layers.Dense(200, activation=\"relu\")(x1)\n",
        "# x1 = layers.Dropout(.1)(x1)\n",
        "x1 = layers.Dense(200, activation=\"linear\", name=\"next_pred\")(x1)\n",
        "\n",
        "# Gender Classification\n",
        "x2 = layers.Dropout(dropout_rate)(x2)\n",
        "x2 = layers.Dense(20, activation=\"relu\")(x2)\n",
        "x2 = layers.Dropout(dropout_rate)(x2)\n",
        "x2 = layers.Dense(1, activation=\"sigmoid\", name=\"gender\")(x2)\n",
        "# x2 = layers.Dense(1, activation=\"sigmoid\")(x2)\n",
        "# x = layers.Dropout(dropout_rate)(x)\n",
        "# x = layers.Dense(20, activation=\"relu\")(x)\n",
        "# x = layers.Dropout(dropout_rate)(x)\n",
        "# x = layers.Dense(1, activation=\"sigmoid\", name=\"gender\")(x)\n",
        "\n",
        "# Age Prediction\n",
        "x3 = layers.Dropout(dropout_rate )(x3)\n",
        "x3 = layers.Dense(20, activation=\"relu\")(x3)\n",
        "x3 = layers.Dropout(dropout_rate)(x3)\n",
        "x3 = layers.Dense(1, activation=\"linear\", name=\"age\")(x3)\n",
        "\n",
        "# ASD Classification\n",
        "x4 = layers.Dropout(dropout_rate)(x4)\n",
        "x4 = layers.Dense(20, activation=\"relu\")(x4)\n",
        "x4 = layers.Dropout(dropout_rate)(x4)\n",
        "x4 = layers.Dense(1, activation=\"sigmoid\", name=\"asd\")(x4)\n",
        "# x2 = layers.Dense(1, activation=\"sigmoid\")(x2)\n",
        "# x = layers.Dropout(dropout_rate)(x)\n",
        "# x = layers.Dense(20, activation=\"relu\")(x)\n",
        "# x = layers.Dropout(dropout_rate)(x)\n",
        "# x = layers.Dense(1, activation=\"sigmoid\", name=\"gender\")(x)\n",
        "outputs = [x1, x2, x3, x4]\n",
        "# outputs = x1\n",
        "\n",
        "\n",
        "model_embed = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# loss = custom_loss(recall_weight=0.9, spec_weight=0.1)\n",
        "# metrics = [tf.keras.metrics.TruePositives(), tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()]\n",
        "# metrics = [recall, precision, specificity]\n",
        "# metrics = ['mse', vec_dist_loss]\n",
        "\n",
        "# opt = keras.optimizers.Adam(learning_rate=0.1)\n",
        "loss_weights = [1e-2,0,1e-2, 1]\n",
        "# loss_weights = [1,0,0]\n",
        "\n",
        "model_embed.compile(loss=[vec_dist_loss, 'binary_crossentropy', 'mse', 'binary_crossentropy'], \n",
        "                    optimizer='adam', metrics={'gender': 'accuracy', 'asd': 'accuracy'}\n",
        "                    , loss_weights=loss_weights)\n",
        "# model_embed.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model_embed.compile(loss=vec_dist_loss, optimizer='adam', metrics=[vec_dist_loss])\n",
        "model_embed.summary()"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_35 (InputLayer)           [(None, 94, 200)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "position_embedding_33 (Position (None, 94, 200)      18800       input_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "transformer_block_33 (Transform (None, 94, 200)      1298832     position_embedding_33[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_103 (S (None, 200)          0           transformer_block_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_104 (S (None, 200)          0           transformer_block_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_105 (S (None, 200)          0           transformer_block_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_102 (S (None, 200)          0           transformer_block_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_240 (Dropout)           (None, 200)          0           tf.__operators__.getitem_103[0][0\n",
            "__________________________________________________________________________________________________\n",
            "dropout_242 (Dropout)           (None, 200)          0           tf.__operators__.getitem_104[0][0\n",
            "__________________________________________________________________________________________________\n",
            "dropout_244 (Dropout)           (None, 200)          0           tf.__operators__.getitem_105[0][0\n",
            "__________________________________________________________________________________________________\n",
            "dropout_239 (Dropout)           (None, 200)          0           tf.__operators__.getitem_102[0][0\n",
            "__________________________________________________________________________________________________\n",
            "dense_171 (Dense)               (None, 20)           4020        dropout_240[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_172 (Dense)               (None, 20)           4020        dropout_242[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_173 (Dense)               (None, 20)           4020        dropout_244[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_170 (Dense)               (None, 200)          40200       dropout_239[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_241 (Dropout)           (None, 20)           0           dense_171[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_243 (Dropout)           (None, 20)           0           dense_172[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_245 (Dropout)           (None, 20)           0           dense_173[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "next_pred (Dense)               (None, 200)          40200       dense_170[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gender (Dense)                  (None, 1)            21          dropout_241[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "age (Dense)                     (None, 1)            21          dropout_243[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "asd (Dense)                     (None, 1)            21          dropout_245[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,410,155\n",
            "Trainable params: 1,410,155\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIn2jgEbO_Y-",
        "outputId": "92520fb3-d1e3-4cb5-84e8-7304c3b641f5"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 100\n",
        "# es_callback = keras.callbacks.EarlyStopping(monitor='val_vec_dist_loss', patience=15)\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='loss', patience=8)\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "history = model_embed.fit(train_X_t, [train_Y_pred_n, train_Y_gen, train_Y_age, train_Y_asd], batch_size=batch_size, epochs=epochs, validation_data=(val_X_t, [val_Y_pred_n, val_Y_gen, val_Y_age, val_Y_asd]), callbacks=[es_callback, lr_callback])\n",
        "# history = model_embed.fit(train_X_t, train_Y_pred_n, batch_size=batch_size, epochs=epochs, validation_data=(val_X_t, val_Y_pred_n), callbacks=[es_callback, lr_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "253/253 [==============================] - 13s 43ms/step - loss: 4.3625 - next_pred_loss: 240.8962 - gender_loss: 0.8435 - age_loss: 118.1251 - asd_loss: 0.7723 - gender_accuracy: 0.5958 - asd_accuracy: 0.5012 - val_loss: 2.8960 - val_next_pred_loss: 162.0823 - val_gender_loss: 0.6455 - val_age_loss: 58.2010 - val_asd_loss: 0.6932 - val_gender_accuracy: 0.8060 - val_asd_accuracy: 0.5029\n",
            "Epoch 2/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.5872 - next_pred_loss: 218.0708 - gender_loss: 1.0747 - age_loss: 71.2725 - asd_loss: 0.6938 - gender_accuracy: 0.5160 - asd_accuracy: 0.5170 - val_loss: 3.0090 - val_next_pred_loss: 162.0907 - val_gender_loss: 0.4601 - val_age_loss: 69.4680 - val_asd_loss: 0.6934 - val_gender_accuracy: 0.8757 - val_asd_accuracy: 0.5029\n",
            "Epoch 3/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 3.3748 - next_pred_loss: 205.3709 - gender_loss: 1.0886 - age_loss: 62.7367 - asd_loss: 0.6937 - gender_accuracy: 0.5181 - asd_accuracy: 0.5146 - val_loss: 2.8349 - val_next_pred_loss: 162.0915 - val_gender_loss: 0.6424 - val_age_loss: 52.0403 - val_asd_loss: 0.6936 - val_gender_accuracy: 0.6161 - val_asd_accuracy: 0.5029\n",
            "Epoch 4/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 3.3975 - next_pred_loss: 218.4769 - gender_loss: 1.0248 - age_loss: 52.0281 - asd_loss: 0.6925 - gender_accuracy: 0.5416 - asd_accuracy: 0.5165 - val_loss: 2.7211 - val_next_pred_loss: 162.0807 - val_gender_loss: 0.6547 - val_age_loss: 40.6776 - val_asd_loss: 0.6936 - val_gender_accuracy: 0.6167 - val_asd_accuracy: 0.5029\n",
            "Epoch 5/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 3.2941 - next_pred_loss: 214.6264 - gender_loss: 1.1897 - age_loss: 45.4961 - asd_loss: 0.6929 - gender_accuracy: 0.5121 - asd_accuracy: 0.5170 - val_loss: 2.6802 - val_next_pred_loss: 162.0821 - val_gender_loss: 0.4302 - val_age_loss: 36.5702 - val_asd_loss: 0.6937 - val_gender_accuracy: 0.8862 - val_asd_accuracy: 0.5029\n",
            "Epoch 6/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.2891 - next_pred_loss: 214.6790 - gender_loss: 1.0919 - age_loss: 44.9714 - asd_loss: 0.6926 - gender_accuracy: 0.5445 - asd_accuracy: 0.5194 - val_loss: 2.6330 - val_next_pred_loss: 162.0841 - val_gender_loss: 0.5063 - val_age_loss: 31.8510 - val_asd_loss: 0.6936 - val_gender_accuracy: 0.8833 - val_asd_accuracy: 0.5029\n",
            "Epoch 7/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.2823 - next_pred_loss: 219.0876 - gender_loss: 1.0483 - age_loss: 39.9563 - asd_loss: 0.6919 - gender_accuracy: 0.5548 - asd_accuracy: 0.5228 - val_loss: 2.7698 - val_next_pred_loss: 162.0821 - val_gender_loss: 0.5380 - val_age_loss: 45.6214 - val_asd_loss: 0.6927 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5029\n",
            "Epoch 8/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.1375 - next_pred_loss: 206.2220 - gender_loss: 1.1093 - age_loss: 38.2622 - asd_loss: 0.6927 - gender_accuracy: 0.5408 - asd_accuracy: 0.5182 - val_loss: 2.7245 - val_next_pred_loss: 162.0858 - val_gender_loss: 0.5367 - val_age_loss: 40.9918 - val_asd_loss: 0.6938 - val_gender_accuracy: 0.8740 - val_asd_accuracy: 0.5046\n",
            "Epoch 9/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.2650 - next_pred_loss: 221.0668 - gender_loss: 1.0956 - age_loss: 36.1558 - asd_loss: 0.6927 - gender_accuracy: 0.5427 - asd_accuracy: 0.5181 - val_loss: 2.7247 - val_next_pred_loss: 162.0930 - val_gender_loss: 0.5535 - val_age_loss: 41.0241 - val_asd_loss: 0.6935 - val_gender_accuracy: 0.8810 - val_asd_accuracy: 0.4948\n",
            "Epoch 10/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.1805 - next_pred_loss: 213.0943 - gender_loss: 1.1894 - age_loss: 35.7470 - asd_loss: 0.6921 - gender_accuracy: 0.5120 - asd_accuracy: 0.5225 - val_loss: 2.6428 - val_next_pred_loss: 162.1047 - val_gender_loss: 0.6127 - val_age_loss: 32.7786 - val_asd_loss: 0.6940 - val_gender_accuracy: 0.8240 - val_asd_accuracy: 0.4942\n",
            "Epoch 11/100\n",
            "253/253 [==============================] - 10s 42ms/step - loss: 3.1807 - next_pred_loss: 216.0185 - gender_loss: 1.1227 - age_loss: 32.9354 - asd_loss: 0.6912 - gender_accuracy: 0.5233 - asd_accuracy: 0.5303 - val_loss: 2.6494 - val_next_pred_loss: 162.0797 - val_gender_loss: 0.5420 - val_age_loss: 33.6358 - val_asd_loss: 0.6923 - val_gender_accuracy: 0.8577 - val_asd_accuracy: 0.5221\n",
            "Epoch 12/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 3.1761 - next_pred_loss: 216.2117 - gender_loss: 1.0518 - age_loss: 32.7119 - asd_loss: 0.6869 - gender_accuracy: 0.5457 - asd_accuracy: 0.5466 - val_loss: 2.6966 - val_next_pred_loss: 162.0768 - val_gender_loss: 0.4633 - val_age_loss: 38.6155 - val_asd_loss: 0.6897 - val_gender_accuracy: 0.8827 - val_asd_accuracy: 0.5407\n",
            "Epoch 13/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 3.0965 - next_pred_loss: 209.1532 - gender_loss: 0.9360 - age_loss: 32.0733 - asd_loss: 0.6842 - gender_accuracy: 0.5951 - asd_accuracy: 0.5413 - val_loss: 2.7312 - val_next_pred_loss: 162.0826 - val_gender_loss: 0.4239 - val_age_loss: 41.7236 - val_asd_loss: 0.6931 - val_gender_accuracy: 0.8862 - val_asd_accuracy: 0.5354\n",
            "Epoch 14/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.0613 - next_pred_loss: 207.4163 - gender_loss: 0.9277 - age_loss: 32.7233 - asd_loss: 0.6599 - gender_accuracy: 0.5798 - asd_accuracy: 0.5870 - val_loss: 2.8582 - val_next_pred_loss: 162.0867 - val_gender_loss: 0.4587 - val_age_loss: 45.4212 - val_asd_loss: 0.7831 - val_gender_accuracy: 0.8728 - val_asd_accuracy: 0.5708\n",
            "Epoch 15/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.0844 - next_pred_loss: 212.9196 - gender_loss: 1.0040 - age_loss: 32.5064 - asd_loss: 0.6302 - gender_accuracy: 0.5569 - asd_accuracy: 0.6234 - val_loss: 2.8871 - val_next_pred_loss: 162.0854 - val_gender_loss: 0.4418 - val_age_loss: 46.4271 - val_asd_loss: 0.8019 - val_gender_accuracy: 0.8862 - val_asd_accuracy: 0.5569\n",
            "Epoch 16/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.1483 - next_pred_loss: 222.0391 - gender_loss: 0.9416 - age_loss: 32.9509 - asd_loss: 0.5984 - gender_accuracy: 0.5735 - asd_accuracy: 0.6728 - val_loss: 2.8651 - val_next_pred_loss: 162.0847 - val_gender_loss: 0.4430 - val_age_loss: 41.7870 - val_asd_loss: 0.8264 - val_gender_accuracy: 0.8862 - val_asd_accuracy: 0.5772\n",
            "Epoch 17/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 3.0838 - next_pred_loss: 224.1966 - gender_loss: 0.9260 - age_loss: 30.0480 - asd_loss: 0.5413 - gender_accuracy: 0.5803 - asd_accuracy: 0.7248 - val_loss: 2.9657 - val_next_pred_loss: 162.0865 - val_gender_loss: 0.4908 - val_age_loss: 43.4202 - val_asd_loss: 0.9106 - val_gender_accuracy: 0.8525 - val_asd_accuracy: 0.6063\n",
            "Epoch 18/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.8933 - next_pred_loss: 213.1139 - gender_loss: 0.9293 - age_loss: 28.5108 - asd_loss: 0.4771 - gender_accuracy: 0.5606 - asd_accuracy: 0.7845 - val_loss: 2.9373 - val_next_pred_loss: 162.0868 - val_gender_loss: 0.4354 - val_age_loss: 40.9678 - val_asd_loss: 0.9068 - val_gender_accuracy: 0.8833 - val_asd_accuracy: 0.5993\n",
            "Epoch 19/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.9704 - next_pred_loss: 228.0736 - gender_loss: 0.8838 - age_loss: 30.1051 - asd_loss: 0.3886 - gender_accuracy: 0.5804 - asd_accuracy: 0.8502 - val_loss: 3.5432 - val_next_pred_loss: 162.0857 - val_gender_loss: 0.4382 - val_age_loss: 37.3508 - val_asd_loss: 1.5489 - val_gender_accuracy: 0.8682 - val_asd_accuracy: 0.5784\n",
            "Epoch 20/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.8040 - next_pred_loss: 218.6867 - gender_loss: 0.8960 - age_loss: 28.1427 - asd_loss: 0.3358 - gender_accuracy: 0.5797 - asd_accuracy: 0.8855 - val_loss: 3.1991 - val_next_pred_loss: 162.0848 - val_gender_loss: 0.4660 - val_age_loss: 42.4200 - val_asd_loss: 1.1541 - val_gender_accuracy: 0.8705 - val_asd_accuracy: 0.6074\n",
            "Epoch 21/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.8200 - next_pred_loss: 226.1691 - gender_loss: 0.9106 - age_loss: 27.8422 - asd_loss: 0.2799 - gender_accuracy: 0.5699 - asd_accuracy: 0.9143 - val_loss: 3.7597 - val_next_pred_loss: 162.0812 - val_gender_loss: 0.4462 - val_age_loss: 40.4895 - val_asd_loss: 1.7340 - val_gender_accuracy: 0.8746 - val_asd_accuracy: 0.5685\n",
            "Epoch 22/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.5150 - next_pred_loss: 204.1785 - gender_loss: 0.9003 - age_loss: 28.0030 - asd_loss: 0.1931 - gender_accuracy: 0.5594 - asd_accuracy: 0.9428 - val_loss: 3.9929 - val_next_pred_loss: 162.0828 - val_gender_loss: 0.4508 - val_age_loss: 43.3509 - val_asd_loss: 1.9386 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5976\n",
            "Epoch 23/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.5737 - next_pred_loss: 215.2900 - gender_loss: 0.8975 - age_loss: 27.8462 - asd_loss: 0.1423 - gender_accuracy: 0.5729 - asd_accuracy: 0.9584 - val_loss: 4.2552 - val_next_pred_loss: 162.0833 - val_gender_loss: 0.4252 - val_age_loss: 42.2133 - val_asd_loss: 2.2122 - val_gender_accuracy: 0.8850 - val_asd_accuracy: 0.5830\n",
            "Epoch 24/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.4529 - next_pred_loss: 207.0033 - gender_loss: 0.8513 - age_loss: 27.2506 - asd_loss: 0.1104 - gender_accuracy: 0.5966 - asd_accuracy: 0.9692 - val_loss: 4.7604 - val_next_pred_loss: 162.0822 - val_gender_loss: 0.4429 - val_age_loss: 37.9949 - val_asd_loss: 2.7596 - val_gender_accuracy: 0.8844 - val_asd_accuracy: 0.5499\n",
            "Epoch 25/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 2.4950 - next_pred_loss: 212.9743 - gender_loss: 0.8747 - age_loss: 27.6460 - asd_loss: 0.0888 - gender_accuracy: 0.5879 - asd_accuracy: 0.9764 - val_loss: 5.0600 - val_next_pred_loss: 162.0820 - val_gender_loss: 0.4345 - val_age_loss: 39.8332 - val_asd_loss: 3.0409 - val_gender_accuracy: 0.8827 - val_asd_accuracy: 0.5720\n",
            "Epoch 26/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.5287 - next_pred_loss: 219.1345 - gender_loss: 0.8608 - age_loss: 25.9337 - asd_loss: 0.0780 - gender_accuracy: 0.5875 - asd_accuracy: 0.9778 - val_loss: 5.0179 - val_next_pred_loss: 162.0814 - val_gender_loss: 0.4415 - val_age_loss: 36.5144 - val_asd_loss: 3.0319 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5540\n",
            "Epoch 27/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3751 - next_pred_loss: 204.7842 - gender_loss: 0.8514 - age_loss: 26.5203 - asd_loss: 0.0621 - gender_accuracy: 0.5849 - asd_accuracy: 0.9858 - val_loss: 5.0502 - val_next_pred_loss: 162.0832 - val_gender_loss: 0.4359 - val_age_loss: 38.6490 - val_asd_loss: 3.0428 - val_gender_accuracy: 0.8844 - val_asd_accuracy: 0.5807\n",
            "Epoch 28/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3931 - next_pred_loss: 204.5710 - gender_loss: 0.8487 - age_loss: 27.4388 - asd_loss: 0.0730 - gender_accuracy: 0.5929 - asd_accuracy: 0.9817 - val_loss: 4.8991 - val_next_pred_loss: 162.0866 - val_gender_loss: 0.4167 - val_age_loss: 41.2815 - val_asd_loss: 2.8654 - val_gender_accuracy: 0.8862 - val_asd_accuracy: 0.5865\n",
            "Epoch 29/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.5202 - next_pred_loss: 219.5139 - gender_loss: 0.8500 - age_loss: 27.0872 - asd_loss: 0.0542 - gender_accuracy: 0.5859 - asd_accuracy: 0.9870 - val_loss: 5.2166 - val_next_pred_loss: 162.0866 - val_gender_loss: 0.4247 - val_age_loss: 38.3020 - val_asd_loss: 3.2127 - val_gender_accuracy: 0.8827 - val_asd_accuracy: 0.5830\n",
            "Epoch 30/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.4684 - next_pred_loss: 215.4760 - gender_loss: 0.8450 - age_loss: 26.5735 - asd_loss: 0.0479 - gender_accuracy: 0.5922 - asd_accuracy: 0.9892 - val_loss: 5.3876 - val_next_pred_loss: 162.0855 - val_gender_loss: 0.4270 - val_age_loss: 35.9786 - val_asd_loss: 3.4070 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5848\n",
            "Epoch 31/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.4977 - next_pred_loss: 219.0402 - gender_loss: 0.8596 - age_loss: 26.2713 - asd_loss: 0.0446 - gender_accuracy: 0.5902 - asd_accuracy: 0.9897 - val_loss: 5.5283 - val_next_pred_loss: 162.0845 - val_gender_loss: 0.4331 - val_age_loss: 37.0915 - val_asd_loss: 3.5366 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5813\n",
            "Epoch 32/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3188 - next_pred_loss: 203.6790 - gender_loss: 0.8560 - age_loss: 24.1036 - asd_loss: 0.0409 - gender_accuracy: 0.5921 - asd_accuracy: 0.9917 - val_loss: 5.8270 - val_next_pred_loss: 162.0855 - val_gender_loss: 0.4282 - val_age_loss: 36.6625 - val_asd_loss: 3.8395 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5767\n",
            "Epoch 33/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3047 - next_pred_loss: 201.7724 - gender_loss: 0.8268 - age_loss: 24.4422 - asd_loss: 0.0426 - gender_accuracy: 0.5962 - asd_accuracy: 0.9902 - val_loss: 5.7578 - val_next_pred_loss: 162.0875 - val_gender_loss: 0.4313 - val_age_loss: 38.9848 - val_asd_loss: 3.7471 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5738\n",
            "Epoch 34/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3896 - next_pred_loss: 209.7247 - gender_loss: 0.8598 - age_loss: 25.1529 - asd_loss: 0.0408 - gender_accuracy: 0.5924 - asd_accuracy: 0.9929 - val_loss: 5.7393 - val_next_pred_loss: 162.0888 - val_gender_loss: 0.4346 - val_age_loss: 39.3375 - val_asd_loss: 3.7250 - val_gender_accuracy: 0.8850 - val_asd_accuracy: 0.5819\n",
            "Epoch 35/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3835 - next_pred_loss: 210.2479 - gender_loss: 0.8449 - age_loss: 24.3159 - asd_loss: 0.0378 - gender_accuracy: 0.5831 - asd_accuracy: 0.9911 - val_loss: 6.0185 - val_next_pred_loss: 162.0879 - val_gender_loss: 0.4319 - val_age_loss: 38.6253 - val_asd_loss: 4.0113 - val_gender_accuracy: 0.8850 - val_asd_accuracy: 0.5842\n",
            "Epoch 36/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3044 - next_pred_loss: 202.8845 - gender_loss: 0.8660 - age_loss: 24.3004 - asd_loss: 0.0326 - gender_accuracy: 0.5925 - asd_accuracy: 0.9896 - val_loss: 6.2264 - val_next_pred_loss: 162.0876 - val_gender_loss: 0.4260 - val_age_loss: 37.9912 - val_asd_loss: 4.2256 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5743\n",
            "Epoch 37/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.4151 - next_pred_loss: 212.2012 - gender_loss: 0.8711 - age_loss: 26.1660 - asd_loss: 0.0314 - gender_accuracy: 0.5843 - asd_accuracy: 0.9902 - val_loss: 6.2829 - val_next_pred_loss: 162.0875 - val_gender_loss: 0.4313 - val_age_loss: 39.0000 - val_asd_loss: 4.2721 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5645\n",
            "Epoch 38/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3029 - next_pred_loss: 203.2927 - gender_loss: 0.8782 - age_loss: 24.1837 - asd_loss: 0.0281 - gender_accuracy: 0.5780 - asd_accuracy: 0.9908 - val_loss: 6.4380 - val_next_pred_loss: 162.0878 - val_gender_loss: 0.4390 - val_age_loss: 38.6590 - val_asd_loss: 4.4305 - val_gender_accuracy: 0.8827 - val_asd_accuracy: 0.5662\n",
            "Epoch 39/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.4801 - next_pred_loss: 221.0693 - gender_loss: 0.8844 - age_loss: 24.0934 - asd_loss: 0.0285 - gender_accuracy: 0.5796 - asd_accuracy: 0.9905 - val_loss: 6.4069 - val_next_pred_loss: 162.0876 - val_gender_loss: 0.4375 - val_age_loss: 38.0864 - val_asd_loss: 4.4052 - val_gender_accuracy: 0.8833 - val_asd_accuracy: 0.5743\n",
            "Epoch 40/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 2.4139 - next_pred_loss: 214.8895 - gender_loss: 0.8658 - age_loss: 23.7353 - asd_loss: 0.0276 - gender_accuracy: 0.5811 - asd_accuracy: 0.9922 - val_loss: 6.4766 - val_next_pred_loss: 162.0871 - val_gender_loss: 0.4392 - val_age_loss: 38.7712 - val_asd_loss: 4.4680 - val_gender_accuracy: 0.8844 - val_asd_accuracy: 0.5679\n",
            "Epoch 41/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 2.2672 - next_pred_loss: 200.1018 - gender_loss: 0.8506 - age_loss: 23.8533 - asd_loss: 0.0277 - gender_accuracy: 0.5907 - asd_accuracy: 0.9921 - val_loss: 6.5381 - val_next_pred_loss: 162.0872 - val_gender_loss: 0.4411 - val_age_loss: 37.0770 - val_asd_loss: 4.5465 - val_gender_accuracy: 0.8833 - val_asd_accuracy: 0.5708\n",
            "Epoch 42/100\n",
            "253/253 [==============================] - 11s 42ms/step - loss: 2.3331 - next_pred_loss: 207.0870 - gender_loss: 0.8715 - age_loss: 23.6418 - asd_loss: 0.0258 - gender_accuracy: 0.5857 - asd_accuracy: 0.9907 - val_loss: 6.5553 - val_next_pred_loss: 162.0868 - val_gender_loss: 0.4423 - val_age_loss: 38.7206 - val_asd_loss: 4.5472 - val_gender_accuracy: 0.8827 - val_asd_accuracy: 0.5732\n",
            "Epoch 43/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.4685 - next_pred_loss: 220.3042 - gender_loss: 0.8751 - age_loss: 23.9138 - asd_loss: 0.0263 - gender_accuracy: 0.5815 - asd_accuracy: 0.9913 - val_loss: 6.4814 - val_next_pred_loss: 162.0869 - val_gender_loss: 0.4401 - val_age_loss: 37.1653 - val_asd_loss: 4.4889 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5691\n",
            "Epoch 44/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.2324 - next_pred_loss: 196.8114 - gender_loss: 0.8688 - age_loss: 23.7885 - asd_loss: 0.0264 - gender_accuracy: 0.5830 - asd_accuracy: 0.9908 - val_loss: 6.6409 - val_next_pred_loss: 162.0871 - val_gender_loss: 0.4392 - val_age_loss: 38.8844 - val_asd_loss: 4.6312 - val_gender_accuracy: 0.8856 - val_asd_accuracy: 0.5743\n",
            "Epoch 45/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.4440 - next_pred_loss: 216.4411 - gender_loss: 0.8785 - age_loss: 25.2197 - asd_loss: 0.0274 - gender_accuracy: 0.5736 - asd_accuracy: 0.9906 - val_loss: 6.7560 - val_next_pred_loss: 162.0870 - val_gender_loss: 0.4391 - val_age_loss: 37.9721 - val_asd_loss: 4.7554 - val_gender_accuracy: 0.8844 - val_asd_accuracy: 0.5714\n",
            "Epoch 46/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3393 - next_pred_loss: 205.9056 - gender_loss: 0.8716 - age_loss: 25.5391 - asd_loss: 0.0249 - gender_accuracy: 0.5808 - asd_accuracy: 0.9926 - val_loss: 6.7135 - val_next_pred_loss: 162.0875 - val_gender_loss: 0.4403 - val_age_loss: 38.1807 - val_asd_loss: 4.7108 - val_gender_accuracy: 0.8839 - val_asd_accuracy: 0.5708\n",
            "Epoch 47/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.2872 - next_pred_loss: 202.0941 - gender_loss: 0.8817 - age_loss: 24.1818 - asd_loss: 0.0245 - gender_accuracy: 0.5734 - asd_accuracy: 0.9915 - val_loss: 6.8599 - val_next_pred_loss: 162.0874 - val_gender_loss: 0.4411 - val_age_loss: 38.4658 - val_asd_loss: 4.8543 - val_gender_accuracy: 0.8833 - val_asd_accuracy: 0.5720\n",
            "Epoch 48/100\n",
            "253/253 [==============================] - 10s 41ms/step - loss: 2.3769 - next_pred_loss: 211.2149 - gender_loss: 0.8847 - age_loss: 24.2995 - asd_loss: 0.0217 - gender_accuracy: 0.5728 - asd_accuracy: 0.9935 - val_loss: 6.7857 - val_next_pred_loss: 162.0874 - val_gender_loss: 0.4406 - val_age_loss: 38.3618 - val_asd_loss: 4.7812 - val_gender_accuracy: 0.8833 - val_asd_accuracy: 0.5738\n",
            "Epoch 49/100\n",
            "187/253 [=====================>........] - ETA: 2s - loss: 2.2491 - next_pred_loss: 198.0940 - gender_loss: 0.8763 - age_loss: 23.9277 - asd_loss: 0.0289 - gender_accuracy: 0.5741 - asd_accuracy: 0.9923"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHP9BSJEPuzC"
      },
      "source": [
        "del model_embed"
      ],
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb2cuYrfPB4J"
      },
      "source": [
        "# evaluate the model\n",
        "# _, train_mse, train_vec_dist = model_embed.evaluate(train_X_t, train_Y_t, verbose=0)\n",
        "# _, test_mse, test_vec_dist = model_embed.evaluate(test_X_t, test_Y_t, verbose=0)\n",
        "# print('Loss: Train: %.3f, Test: %.3f' % (train_vec_dist, test_vec_dist))\n",
        "# print('MSE: Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
        "train_acc = model_embed.evaluate(train_X_t, [train_Y_pred_n, train_Y_gen, train_Y_age], verbose=0)\n",
        "test_acc = model_embed.evaluate(test_X_t, [test_Y_pred_n, test_Y_gen, test_Y_age], verbose=0)\n",
        "print('Train:')\n",
        "print(train_acc)\n",
        "print('Test:')\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "92CMBDEbudYt",
        "outputId": "7be0b314-a105-4919-8b27-e658ea346e0c"
      },
      "source": [
        "def plt_training(var, skip=0, exp_name=None):\n",
        "  plt.plot(history.history[var][skip:])\n",
        "  plt.plot(history.history['val_' + var][skip:])\n",
        "  plt.title('model ' + var)\n",
        "  plt.ylabel(var)\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "  if exp_name is not None:\n",
        "    plt.savefig(f'{exp_name}_{var}.png')\n",
        "\n",
        "exp_name = 'L90_8_32_asd_nogen'\n",
        "vars = ['loss', 'next_pred_loss', 'gender_loss', 'age_loss','asd_loss', 'gender_accuracy', 'asd_accuracy']\n",
        "skip = 1\n",
        "plt_training(vars[5], skip, exp_name)"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvUHSprOP4cH",
        "outputId": "4eb0d3d5-c7ae-4bee-d494-4ebf8b187eb9"
      },
      "source": [
        "train_X_t.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65160, 13, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSJSGGCTIVQ4",
        "outputId": "5833c286-369e-440e-9b20-54954ef2b6c3"
      },
      "source": [
        "x = train_X_t[10]\n",
        "x = np.array([x])\n",
        "pred_1 = model_embed.predict(x)\n",
        "print(pred[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-5.80685353e-03  7.00870901e-03 -5.30468533e-03 -4.67797928e-03\n",
            "  -8.40399228e-03 -2.01184792e-03  1.57812634e-03  5.49251586e-03\n",
            "   3.36841517e-03 -4.92243189e-03  1.12116523e-02  7.91327562e-03\n",
            "   1.58481445e-04  1.01462258e-02 -2.61165504e-03 -9.14084550e-04\n",
            "   9.11390758e-04 -1.43703781e-02  1.08394306e-03  9.33996961e-03\n",
            "  -1.86318671e-03 -7.21908547e-03  1.07470239e-02  1.47122890e-03\n",
            "  -4.00586141e-04 -3.58088571e-03 -1.58564723e-03 -2.57585035e-03\n",
            "   6.79692579e-03 -1.32695604e-02  4.04647598e-03  9.52751748e-03\n",
            "  -7.86024961e-04 -4.39785683e-04 -9.74613335e-03  5.88800851e-03\n",
            "  -3.40825506e-03  7.20302109e-03  9.68248211e-03  2.39070365e-03\n",
            "  -3.72078526e-03  9.15440358e-03 -7.45086232e-04 -3.06080421e-03\n",
            "  -5.42938011e-03  1.12202931e-02 -8.89557693e-03 -9.51128732e-03\n",
            "   9.08031315e-03  2.76662200e-03 -2.32608698e-04 -7.91576691e-03\n",
            "   1.62039883e-02  6.21570554e-03  1.74448406e-03  6.97453413e-03\n",
            "   4.26503364e-03  7.52499327e-05  5.50327869e-03  5.34584187e-03\n",
            "   5.86211309e-03 -2.61871773e-03  3.68111068e-03  1.33841280e-02\n",
            "   1.02514867e-04  3.32588656e-03 -1.12777005e-03 -6.88633043e-03\n",
            "   3.13625969e-02 -2.31692917e-04  1.24289710e-02  1.16336942e-02\n",
            "   1.41862510e-02  1.65190250e-02  1.01939347e-02  9.82210878e-03\n",
            "   1.09487567e-02  1.03775822e-02  2.60334855e-05  1.37509396e-02\n",
            "   9.54514742e-03  2.07393803e-02  1.27504654e-02  2.71242578e-03\n",
            "   4.10556421e-03  6.78405631e-04  3.53431539e-03 -2.53164675e-03\n",
            "   5.44924615e-03  6.50125695e-03  1.40400818e-02 -2.71831919e-03\n",
            "   1.54034505e-02  3.79793113e-03  5.71937067e-03  1.06540732e-02\n",
            "   1.13330279e-02  4.83484194e-03  9.54599772e-03  8.71655438e-03\n",
            "   8.79961811e-03  3.53796245e-03  8.31702072e-03  5.64845838e-03\n",
            "   4.44437377e-03  1.39121478e-02  2.21756585e-02  9.08525940e-03\n",
            "  -4.77878144e-04  1.66014656e-02  4.09500953e-03  8.84102844e-03\n",
            "   2.10108142e-02  1.48082888e-02  1.41954832e-02  9.35977791e-03\n",
            "   2.40155943e-02  1.01473108e-02  1.40897324e-03  1.03119183e-02\n",
            "  -1.26818405e-03  4.58299974e-03  6.81161042e-03  1.32084899e-02\n",
            "   2.02736557e-02  1.73516572e-02  1.81588456e-02  1.37450900e-02\n",
            "   1.00409053e-02  1.20230438e-02  1.23520652e-02  2.24755388e-02\n",
            "   2.42522322e-02  7.36992387e-03  8.87792278e-03  2.19589900e-02\n",
            "   1.28376139e-02  1.11597907e-02  1.39139341e-02  1.17676836e-02\n",
            "   3.56755294e-02  6.50904234e-03  1.46347964e-02  2.31321845e-02\n",
            "   1.28673501e-02  1.64706036e-02  2.25249622e-02  6.81229541e-03\n",
            "   2.31499076e-02  1.26302559e-02  2.64663026e-02  1.64694041e-02\n",
            "   2.51341760e-02  1.48434676e-02  1.69635881e-02  2.78350394e-02\n",
            "   2.02870052e-02  4.21228400e-03  9.61865857e-03  1.50688253e-02\n",
            "   9.67082940e-03  1.54286893e-02  2.01065484e-02  1.56835765e-02\n",
            "   3.34748700e-02  2.31089089e-02  3.16494927e-02  2.02719495e-02\n",
            "   4.04072814e-02  1.47581212e-02  2.40175035e-02  1.23170735e-02\n",
            "   1.59646645e-02  1.93420127e-02  7.16752978e-03  1.21745178e-02\n",
            "   8.24344158e-03  1.03823747e-02  8.02664738e-03  2.29295958e-02\n",
            "   1.74889173e-02  1.76359620e-02  3.86386253e-02  2.93693002e-02\n",
            "   7.12532178e-03  1.80865750e-02  2.60863323e-02  1.65051706e-02\n",
            "   1.63374357e-02  3.34409811e-03  1.85536947e-02  1.84930637e-02\n",
            "   3.02732363e-02  1.28080091e-02  7.52128148e-03  4.35683839e-02\n",
            "   2.16922387e-02  1.62404403e-02  1.92259196e-02  1.93234906e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W08jiXKBR8ys",
        "outputId": "d3618c5d-464b-491b-b858-c614535bde72"
      },
      "source": [
        "sum(pred[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.80685353e-03,  7.00870901e-03, -5.30468533e-03, -4.67797928e-03,\n",
              "       -8.40399228e-03, -2.01184792e-03,  1.57812634e-03,  5.49251586e-03,\n",
              "        3.36841517e-03, -4.92243189e-03,  1.12116523e-02,  7.91327562e-03,\n",
              "        1.58481445e-04,  1.01462258e-02, -2.61165504e-03, -9.14084550e-04,\n",
              "        9.11390758e-04, -1.43703781e-02,  1.08394306e-03,  9.33996961e-03,\n",
              "       -1.86318671e-03, -7.21908547e-03,  1.07470239e-02,  1.47122890e-03,\n",
              "       -4.00586141e-04, -3.58088571e-03, -1.58564723e-03, -2.57585035e-03,\n",
              "        6.79692579e-03, -1.32695604e-02,  4.04647598e-03,  9.52751748e-03,\n",
              "       -7.86024961e-04, -4.39785683e-04, -9.74613335e-03,  5.88800851e-03,\n",
              "       -3.40825506e-03,  7.20302109e-03,  9.68248211e-03,  2.39070365e-03,\n",
              "       -3.72078526e-03,  9.15440358e-03, -7.45086232e-04, -3.06080421e-03,\n",
              "       -5.42938011e-03,  1.12202931e-02, -8.89557693e-03, -9.51128732e-03,\n",
              "        9.08031315e-03,  2.76662200e-03, -2.32608698e-04, -7.91576691e-03,\n",
              "        1.62039883e-02,  6.21570554e-03,  1.74448406e-03,  6.97453413e-03,\n",
              "        4.26503364e-03,  7.52499327e-05,  5.50327869e-03,  5.34584187e-03,\n",
              "        5.86211309e-03, -2.61871773e-03,  3.68111068e-03,  1.33841280e-02,\n",
              "        1.02514867e-04,  3.32588656e-03, -1.12777005e-03, -6.88633043e-03,\n",
              "        3.13625969e-02, -2.31692917e-04,  1.24289710e-02,  1.16336942e-02,\n",
              "        1.41862510e-02,  1.65190250e-02,  1.01939347e-02,  9.82210878e-03,\n",
              "        1.09487567e-02,  1.03775822e-02,  2.60334855e-05,  1.37509396e-02,\n",
              "        9.54514742e-03,  2.07393803e-02,  1.27504654e-02,  2.71242578e-03,\n",
              "        4.10556421e-03,  6.78405631e-04,  3.53431539e-03, -2.53164675e-03,\n",
              "        5.44924615e-03,  6.50125695e-03,  1.40400818e-02, -2.71831919e-03,\n",
              "        1.54034505e-02,  3.79793113e-03,  5.71937067e-03,  1.06540732e-02,\n",
              "        1.13330279e-02,  4.83484194e-03,  9.54599772e-03,  8.71655438e-03,\n",
              "        8.79961811e-03,  3.53796245e-03,  8.31702072e-03,  5.64845838e-03,\n",
              "        4.44437377e-03,  1.39121478e-02,  2.21756585e-02,  9.08525940e-03,\n",
              "       -4.77878144e-04,  1.66014656e-02,  4.09500953e-03,  8.84102844e-03,\n",
              "        2.10108142e-02,  1.48082888e-02,  1.41954832e-02,  9.35977791e-03,\n",
              "        2.40155943e-02,  1.01473108e-02,  1.40897324e-03,  1.03119183e-02,\n",
              "       -1.26818405e-03,  4.58299974e-03,  6.81161042e-03,  1.32084899e-02,\n",
              "        2.02736557e-02,  1.73516572e-02,  1.81588456e-02,  1.37450900e-02,\n",
              "        1.00409053e-02,  1.20230438e-02,  1.23520652e-02,  2.24755388e-02,\n",
              "        2.42522322e-02,  7.36992387e-03,  8.87792278e-03,  2.19589900e-02,\n",
              "        1.28376139e-02,  1.11597907e-02,  1.39139341e-02,  1.17676836e-02,\n",
              "        3.56755294e-02,  6.50904234e-03,  1.46347964e-02,  2.31321845e-02,\n",
              "        1.28673501e-02,  1.64706036e-02,  2.25249622e-02,  6.81229541e-03,\n",
              "        2.31499076e-02,  1.26302559e-02,  2.64663026e-02,  1.64694041e-02,\n",
              "        2.51341760e-02,  1.48434676e-02,  1.69635881e-02,  2.78350394e-02,\n",
              "        2.02870052e-02,  4.21228400e-03,  9.61865857e-03,  1.50688253e-02,\n",
              "        9.67082940e-03,  1.54286893e-02,  2.01065484e-02,  1.56835765e-02,\n",
              "        3.34748700e-02,  2.31089089e-02,  3.16494927e-02,  2.02719495e-02,\n",
              "        4.04072814e-02,  1.47581212e-02,  2.40175035e-02,  1.23170735e-02,\n",
              "        1.59646645e-02,  1.93420127e-02,  7.16752978e-03,  1.21745178e-02,\n",
              "        8.24344158e-03,  1.03823747e-02,  8.02664738e-03,  2.29295958e-02,\n",
              "        1.74889173e-02,  1.76359620e-02,  3.86386253e-02,  2.93693002e-02,\n",
              "        7.12532178e-03,  1.80865750e-02,  2.60863323e-02,  1.65051706e-02,\n",
              "        1.63374357e-02,  3.34409811e-03,  1.85536947e-02,  1.84930637e-02,\n",
              "        3.02732363e-02,  1.28080091e-02,  7.52128148e-03,  4.35683839e-02,\n",
              "        2.16922387e-02,  1.62404403e-02,  1.92259196e-02,  1.93234906e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkLO3Bo2Sc-D",
        "outputId": "7060cf59-45fb-4e4a-906d-483fe68074e3"
      },
      "source": [
        "train_Y_pred_n[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.96294264e-01],\n",
              "       [-1.90173461e+00],\n",
              "       [-1.55800871e+00],\n",
              "       [-6.77506864e-02],\n",
              "       [-4.91607182e-01],\n",
              "       [-6.11012321e-02],\n",
              "       [-1.28264352e-01],\n",
              "       [ 3.69203950e-01],\n",
              "       [-7.05338678e-02],\n",
              "       [ 1.70980964e-01],\n",
              "       [-1.17186140e+00],\n",
              "       [-6.65373203e-01],\n",
              "       [ 2.56720584e-01],\n",
              "       [-1.98820250e+00],\n",
              "       [ 3.29306338e-01],\n",
              "       [-2.02854950e-01],\n",
              "       [-5.47978812e-01],\n",
              "       [-4.88429757e-01],\n",
              "       [-1.10110825e+00],\n",
              "       [ 5.68499307e-01],\n",
              "       [-2.64113917e-02],\n",
              "       [-4.35135597e-01],\n",
              "       [ 6.33459990e-01],\n",
              "       [-4.17110836e-02],\n",
              "       [ 2.87169149e-01],\n",
              "       [ 7.63392462e-02],\n",
              "       [ 1.21443515e-01],\n",
              "       [ 8.32702380e-02],\n",
              "       [-1.70849594e-01],\n",
              "       [-2.16139362e-01],\n",
              "       [ 4.01960511e-01],\n",
              "       [-1.54628007e-01],\n",
              "       [-9.73850244e-01],\n",
              "       [ 3.58519707e-01],\n",
              "       [-7.53234077e-02],\n",
              "       [-2.56345016e-01],\n",
              "       [-6.86558936e-01],\n",
              "       [-6.55186576e-02],\n",
              "       [ 9.66138347e-02],\n",
              "       [-4.52230358e-01],\n",
              "       [-2.52934830e-01],\n",
              "       [-6.59436657e-02],\n",
              "       [-4.68276210e-02],\n",
              "       [ 1.26853884e-01],\n",
              "       [-2.42352257e-01],\n",
              "       [-8.73171953e-01],\n",
              "       [ 1.40478876e-01],\n",
              "       [-4.93066791e-01],\n",
              "       [-4.42978934e-01],\n",
              "       [-1.64805329e-01],\n",
              "       [-4.09213561e-01],\n",
              "       [ 1.24874745e-01],\n",
              "       [-7.44592687e-01],\n",
              "       [ 4.17601696e-01],\n",
              "       [-1.09153225e-01],\n",
              "       [-5.40885108e-01],\n",
              "       [ 2.65859902e-01],\n",
              "       [-1.00294036e+00],\n",
              "       [-9.29808153e-02],\n",
              "       [ 4.27677491e-01],\n",
              "       [-6.03791199e-01],\n",
              "       [ 1.29474696e-01],\n",
              "       [ 1.02356519e-01],\n",
              "       [-2.23505226e-01],\n",
              "       [ 8.72045295e-02],\n",
              "       [-3.25816862e-02],\n",
              "       [ 3.70650007e-01],\n",
              "       [ 3.67937132e-01],\n",
              "       [-6.82055565e-01],\n",
              "       [ 5.89325547e-02],\n",
              "       [ 2.78926250e-01],\n",
              "       [-5.61944010e-01],\n",
              "       [-5.29466156e-01],\n",
              "       [-6.09830431e-01],\n",
              "       [-9.29447145e-01],\n",
              "       [ 1.00067537e-01],\n",
              "       [ 1.76823345e-03],\n",
              "       [-1.00503502e-01],\n",
              "       [ 6.44109867e-01],\n",
              "       [-7.97171310e-02],\n",
              "       [-6.74900533e-01],\n",
              "       [-4.45833837e-02],\n",
              "       [ 1.58621304e-01],\n",
              "       [-2.25228589e-01],\n",
              "       [ 6.35557297e-01],\n",
              "       [-1.49518818e-01],\n",
              "       [-1.41871931e-01],\n",
              "       [-9.61325943e-02],\n",
              "       [-5.53873259e-03],\n",
              "       [ 7.21804281e-02],\n",
              "       [-1.29151835e+00],\n",
              "       [-6.95342910e-02],\n",
              "       [ 6.64694441e-01],\n",
              "       [-5.63624887e-01],\n",
              "       [-8.42161885e-01],\n",
              "       [ 2.43308111e-01],\n",
              "       [-1.35496409e-01],\n",
              "       [ 7.38304876e-01],\n",
              "       [ 3.37238136e-01],\n",
              "       [ 5.71934968e-01],\n",
              "       [-1.23671634e-01],\n",
              "       [-3.11283770e-01],\n",
              "       [-2.96694156e-02],\n",
              "       [ 2.06357021e-01],\n",
              "       [-6.95049206e-01],\n",
              "       [-2.90543231e-01],\n",
              "       [-7.45295630e-01],\n",
              "       [-1.92355719e-01],\n",
              "       [-3.70630200e-01],\n",
              "       [-7.44232710e-02],\n",
              "       [ 1.92570090e-01],\n",
              "       [-1.08780767e-01],\n",
              "       [-1.65328176e-01],\n",
              "       [ 3.18758732e-01],\n",
              "       [-4.83854679e-01],\n",
              "       [ 1.13158726e+00],\n",
              "       [-1.63689862e+00],\n",
              "       [-1.54107133e-01],\n",
              "       [ 3.25432631e-01],\n",
              "       [-3.47141891e-02],\n",
              "       [ 1.49020924e-01],\n",
              "       [-1.62170822e-01],\n",
              "       [ 4.99178839e-01],\n",
              "       [ 8.70932811e-02],\n",
              "       [ 6.16952034e-01],\n",
              "       [-2.38725463e-01],\n",
              "       [ 1.96170007e-01],\n",
              "       [ 2.50093602e-01],\n",
              "       [-1.49595328e-01],\n",
              "       [-1.26848487e-01],\n",
              "       [-2.79043995e-01],\n",
              "       [ 1.30109757e+00],\n",
              "       [-9.11617618e-01],\n",
              "       [ 1.94854812e-01],\n",
              "       [-1.81501945e-02],\n",
              "       [ 4.13283711e-01],\n",
              "       [ 4.12231968e-02],\n",
              "       [-4.41063181e-01],\n",
              "       [-2.52162467e-01],\n",
              "       [-2.06912927e-01],\n",
              "       [-6.24496056e-01],\n",
              "       [-2.83442779e-01],\n",
              "       [ 8.55621841e-01],\n",
              "       [-1.64952602e-01],\n",
              "       [-1.75122176e-01],\n",
              "       [-5.34054544e-02],\n",
              "       [-1.83837963e+00],\n",
              "       [-1.93820303e-01],\n",
              "       [-5.20027659e-01],\n",
              "       [-4.67290399e-01],\n",
              "       [ 2.32145279e-01],\n",
              "       [-3.75917827e-01],\n",
              "       [-6.47981064e-01],\n",
              "       [-1.31516530e-02],\n",
              "       [ 6.64960825e-03],\n",
              "       [ 5.92004329e-01],\n",
              "       [ 2.26964154e-01],\n",
              "       [-3.11530128e-02],\n",
              "       [-7.73995815e-01],\n",
              "       [ 3.19853832e-01],\n",
              "       [ 1.14934815e-01],\n",
              "       [-4.52356061e-02],\n",
              "       [-4.17025063e-02],\n",
              "       [-5.11294237e-02],\n",
              "       [ 2.62473818e-01],\n",
              "       [-2.05695857e-01],\n",
              "       [ 3.04349598e-01],\n",
              "       [-1.74506007e-01],\n",
              "       [ 4.97298310e-01],\n",
              "       [ 2.58552993e-01],\n",
              "       [ 1.39962417e+00],\n",
              "       [-1.98047454e-01],\n",
              "       [-2.63276265e-01],\n",
              "       [-2.10108852e+00],\n",
              "       [-1.66211330e-01],\n",
              "       [-7.98786427e-02],\n",
              "       [-2.39851899e-01],\n",
              "       [-2.64709758e-02],\n",
              "       [-6.66045754e-01],\n",
              "       [ 9.45094757e-01],\n",
              "       [-4.95928627e-01],\n",
              "       [-1.71388280e-01],\n",
              "       [ 2.54211792e-01],\n",
              "       [ 3.84978113e-01],\n",
              "       [-1.82098056e-01],\n",
              "       [-3.89414015e-01],\n",
              "       [-6.77126757e-01],\n",
              "       [-1.68728098e-01],\n",
              "       [-1.74747288e-01],\n",
              "       [ 5.34517655e-02],\n",
              "       [-2.22055138e-01],\n",
              "       [ 2.57051612e-01],\n",
              "       [-1.18692078e+00],\n",
              "       [ 8.53089491e-01],\n",
              "       [ 2.77520907e-01],\n",
              "       [-1.87921883e-01],\n",
              "       [ 8.95614161e-02],\n",
              "       [-4.93148419e-03],\n",
              "       [ 1.53102289e-01],\n",
              "       [-2.78694440e-03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdvpknERahC",
        "outputId": "52501d90-ef42-4dc5-e7b4-26831a1ba1e6"
      },
      "source": [
        "print(vec_dist_loss(pred[0], pred_1[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKyHEPE4w10U"
      },
      "source": [
        "# Pretraining\n",
        "num_heads = 8\n",
        "ff_dim = 32\n",
        "Train:\n",
        "[0.14941030740737915, 0.9942409992218018, 2.342025254620239e-06, 0.0499839149415493, 0.9942409992218018, 1.0, 0.0499839149415493]\n",
        "Test:\n",
        "[8.86508560180664, 1.0045969486236572, 7.8084635734558105, 0.9561624526977539, 1.0045969486236572, 0.5303292870521545, 0.9561624526977539]\n",
        "\n",
        "num_heads = 8\n",
        "ff_dim = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7uirnTeTxKc"
      },
      "source": [
        "num_heads = 8  \n",
        "ff_dim = 32\n",
        "# Gender acc:\n",
        "* .25 drop: Train: 1.000, Test: 0.527\n",
        "* .5 drop: Train: 0.999, Test: 0.520\n",
        "\n",
        "# Age MSE:\n",
        "* .25 drop: Train: 0.024, Test: 1.194\n",
        "* .5 drop: Train: 0.103, Test: 1.277\n",
        "\n",
        "# Next Pred:\n",
        "* .25 drop: \n",
        "* .5 drop: Train: 0.994, Test: 1.000\n",
        "\n",
        "num_heads = 4  \n",
        "ff_dim = 32\n",
        "\n",
        "# Age MSE:\n",
        "* .5 drop: Train: 0.089, Test: 1.297\n",
        "\n",
        "num_heads = 2  \n",
        "ff_dim = 32\n",
        "\n",
        "# Age MSE:\n",
        "Train: 0.196, Test: 1.393"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opjmh2Sdb-4y"
      },
      "source": [
        "x = np.array([train_X_t[15]])\n",
        "a1 = model_embed.predict(x) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luSyTf9rdi-T",
        "outputId": "b5de04d8-944b-433b-e3c0-7d324df1f0df"
      },
      "source": [
        "a2[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.44724545], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1rGDJhtdJcf",
        "outputId": "116052d5-2149-460d-990e-eab9a47e7d17"
      },
      "source": [
        "a1[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.44724545], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYyExf58NlR8"
      },
      "source": [
        "x = np.array([train_X_t[15]])\n",
        "x2 = np.array([train_X_t[16]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdgYJEMINn2i",
        "outputId": "dc681487-f33f-42dd-c7c6-331fc8e95eb2"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [-0.00026516, -0.00479211, -0.01246446, ..., -0.00077214,\n",
              "          0.00492293, -0.00260531],\n",
              "        [-0.00364222, -0.00202805, -0.0139706 , ..., -0.00084743,\n",
              "          0.0077697 , -0.00720413],\n",
              "        ...,\n",
              "        [-0.00709372,  0.01438538,  0.02005716, ...,  0.00049057,\n",
              "          0.00275204,  0.00516073],\n",
              "        [-0.00206024,  0.00569157,  0.0082498 , ...,  0.00015159,\n",
              "         -0.00028173,  0.00468361],\n",
              "        [ 0.00429784, -0.00625803, -0.01116405, ..., -0.00124895,\n",
              "         -0.0043249 ,  0.0007013 ]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC0nn7ZONpOa",
        "outputId": "1be9b325-b9eb-4329-9421-628e95bc9697"
      },
      "source": [
        "x2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "        [-5.26466934e-05,  1.92892672e-03, -5.43647667e-03, ...,\n",
              "         -1.12879740e-04, -3.44300153e-03,  5.06015294e-03],\n",
              "        [-2.87038934e-03, -5.19179349e-03, -1.11219341e-02, ...,\n",
              "          6.37216691e-05, -4.58006537e-03,  5.73129980e-03],\n",
              "        ...,\n",
              "        [ 7.04238153e-03, -3.24570940e-03, -2.58997803e-03, ...,\n",
              "          1.62201403e-03, -3.48030905e-03,  7.16185485e-03],\n",
              "        [-1.80642501e-03, -1.85231210e-03, -4.42355203e-03, ...,\n",
              "          7.24248218e-04, -3.54382731e-03,  5.88919315e-03],\n",
              "        [-1.15515802e-02,  7.53222816e-03, -3.46211729e-03, ...,\n",
              "          1.64056075e-05, -2.54555417e-03,  5.88229557e-03]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}