{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASD_class_pure.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlXSuqibkPBH"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, AveragePooling2D, AveragePooling1D\n",
        "from keras.metrics import BinaryAccuracy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxRknp2ZkEjG"
      },
      "source": [
        "X = np.load('ABIDE_X.npy', allow_pickle=True)\n",
        "Y = np.load('ABIDE_Y.npy', allow_pickle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVB3iCjBkbaI"
      },
      "source": [
        "# Since scans are 2s apart 90 scans is 3 mins\n",
        "L = 90\n",
        "# Number of clips per subject\n",
        "N=10\n",
        "# Number of ROIs\n",
        "N_rois = 200\n",
        "feat_name = 'filt_noglobal_roi_200_Cradd'\n",
        "def extract_feat_sections(data, L=L, N=N):\n",
        "    feat_secs = list()\n",
        "    for i in range(N):\n",
        "        r = int(random.random() * (len(data) - L))\n",
        "        feat_secs.append(data[r:r+L])\n",
        "    return np.array(feat_secs)\n",
        "\n",
        "def create_dataset(X_arr, Y_arr, L=L,N=N):\n",
        "    X = list()\n",
        "    Y = list()\n",
        "    for n, data in enumerate(X_arr):\n",
        "        feat_secs = extract_feat_sections(data)\n",
        "        X.extend(feat_secs)\n",
        "        for i in range(len(feat_secs)):\n",
        "            Y.append(Y_arr[n, 2])\n",
        "    assert len(X) == len(Y)\n",
        "    X_ar = np.array(X).reshape(len(X), L, N_rois)\n",
        "    Y_ar = np.array(Y)\n",
        "    return X_ar, Y_ar"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZboltuclfhn",
        "outputId": "b02cd8fb-68eb-4bcf-ccb8-d3fd731904bb"
      },
      "source": [
        "# In original work 10 fold cross val used with proportion of subjects from each site was approximately the same in all folds\n",
        "# To start will just randomly split subjects into groups\n",
        "random_seed = 52\n",
        "val_per = .05\n",
        "test_per = .1\n",
        "train_sub_X, val_sub_X, train_sub_Y, val_sub_Y = train_test_split(X, Y, test_size=val_per + test_per, random_state=random_seed)\n",
        "val_sub_X, test_sub_X, val_sub_Y, test_sub_Y= train_test_split(val_sub_X, val_sub_Y, test_size=test_per/(val_per + test_per), random_state=random_seed + 1)\n",
        "print(f'{len(train_sub_X)} subjects for training.')\n",
        "print(f'{len(val_sub_X)} subjects for validation')\n",
        "print(f'{len(test_sub_X)} subjects for testing')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "806 subjects for training.\n",
            "47 subjects for validation\n",
            "96 subjects for testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqELC9_Iqm-L",
        "outputId": "e6db9f6b-1504-4dac-e1a7-7bb0801820e6"
      },
      "source": [
        "# Randomly extracts 10 shorter clips from each subject\n",
        "train_X, train_Y = create_dataset(train_sub_X, train_sub_Y)\n",
        "val_X, val_Y = create_dataset(val_sub_X, val_sub_Y)\n",
        "test_X, test_Y = create_dataset(test_sub_X, test_sub_Y)\n",
        "print(f'{len(train_X)} training examples')\n",
        "print(f'{len(val_X)} validation examples')\n",
        "print(f'{len(test_X)} testing examples')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8060 training examples\n",
            "470 validation examples\n",
            "960 testing examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKAnnakonYD8"
      },
      "source": [
        "First evaluate performance of LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-GLxawcnThU",
        "outputId": "393a02dc-f4a6-4781-b49c-7c0390fdf07f"
      },
      "source": [
        "# create and fit the LSTM network\n",
        "# hidden_nodes = int(2/3 * (N_rois * L))\n",
        "hidden_nodes = 16\n",
        "model = Sequential()\n",
        "model.add(LSTM(hidden_nodes, input_shape=(L, N_rois), return_sequences=True, dropout=0.5))\n",
        "model.add(Dropout(0.5))\n",
        "# model.add(LSTM(hidden_nodes))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(AveragePooling2D(pool_size=(L, 1)))\n",
        "model.add(AveragePooling1D(pool_size=L))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 90, 16)            13888     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 90, 16)            0         \n",
            "_________________________________________________________________\n",
            "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1, 1)              17        \n",
            "=================================================================\n",
            "Total params: 13,905\n",
            "Trainable params: 13,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isf-PJSYoCZT",
        "outputId": "2e214d4f-9599-4bed-9e0d-96e59eba2272"
      },
      "source": [
        "\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)\n",
        "history = model.fit(train_X, train_Y, batch_size=batch_size, epochs=epochs, validation_data=(val_X, val_Y), callbacks=[es_callback])\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "252/252 [==============================] - 4s 9ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6859 - val_accuracy: 0.5574\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.6862 - accuracy: 0.5608 - val_loss: 0.7003 - val_accuracy: 0.4745\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.6746 - accuracy: 0.6098 - val_loss: 0.6962 - val_accuracy: 0.5106\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.6557 - accuracy: 0.6607 - val_loss: 0.7057 - val_accuracy: 0.5319\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.6358 - accuracy: 0.6734 - val_loss: 0.7100 - val_accuracy: 0.5574\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.6163 - accuracy: 0.7027 - val_loss: 0.7139 - val_accuracy: 0.5702\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.6027 - accuracy: 0.7034 - val_loss: 0.7125 - val_accuracy: 0.5979\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.5774 - accuracy: 0.7312 - val_loss: 0.7006 - val_accuracy: 0.6191\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.5624 - accuracy: 0.7345 - val_loss: 0.7057 - val_accuracy: 0.6043\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 2s 8ms/step - loss: 0.5464 - accuracy: 0.7474 - val_loss: 0.6885 - val_accuracy: 0.6447\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.5290 - accuracy: 0.7526 - val_loss: 0.6827 - val_accuracy: 0.6404\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.5130 - accuracy: 0.7680 - val_loss: 0.6997 - val_accuracy: 0.6404\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.5069 - accuracy: 0.7602 - val_loss: 0.6938 - val_accuracy: 0.6681\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4886 - accuracy: 0.7847 - val_loss: 0.6926 - val_accuracy: 0.6638\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4915 - accuracy: 0.7776 - val_loss: 0.6776 - val_accuracy: 0.6511\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4799 - accuracy: 0.7836 - val_loss: 0.6669 - val_accuracy: 0.6681\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4750 - accuracy: 0.7814 - val_loss: 0.7450 - val_accuracy: 0.6638\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4566 - accuracy: 0.7967 - val_loss: 0.7641 - val_accuracy: 0.6277\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4577 - accuracy: 0.7944 - val_loss: 0.7193 - val_accuracy: 0.6787\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4375 - accuracy: 0.8127 - val_loss: 0.7425 - val_accuracy: 0.6319\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4370 - accuracy: 0.8033 - val_loss: 0.7822 - val_accuracy: 0.6128\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4217 - accuracy: 0.8190 - val_loss: 0.6886 - val_accuracy: 0.6468\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4201 - accuracy: 0.8232 - val_loss: 0.7152 - val_accuracy: 0.6596\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4288 - accuracy: 0.8042 - val_loss: 0.7212 - val_accuracy: 0.6745\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4126 - accuracy: 0.8179 - val_loss: 0.6900 - val_accuracy: 0.6787\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4121 - accuracy: 0.8219 - val_loss: 0.7326 - val_accuracy: 0.6745\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4053 - accuracy: 0.8256 - val_loss: 0.8119 - val_accuracy: 0.6596\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.3928 - accuracy: 0.8380 - val_loss: 0.8470 - val_accuracy: 0.6447\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.4011 - accuracy: 0.8234 - val_loss: 0.8409 - val_accuracy: 0.6362\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.3981 - accuracy: 0.8234 - val_loss: 0.8241 - val_accuracy: 0.6383\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.3939 - accuracy: 0.8310 - val_loss: 0.8289 - val_accuracy: 0.6340\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 2s 8ms/step - loss: 0.3922 - accuracy: 0.8272 - val_loss: 0.7722 - val_accuracy: 0.6787\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.3786 - accuracy: 0.8362 - val_loss: 0.9117 - val_accuracy: 0.6149\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 2s 7ms/step - loss: 0.3801 - accuracy: 0.8443 - val_loss: 0.9303 - val_accuracy: 0.6383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hviapWvprGZ",
        "outputId": "547a8e68-59e3-43b9-9180-36da8528506e"
      },
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(train_X, train_Y, verbose=0)\n",
        "_, test_acc = model.evaluate(test_X, test_Y, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.910, Test: 0.601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4Hdsi4U2z8C"
      },
      "source": [
        "Now with the Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGynMdxmoT9M",
        "outputId": "97215218-23c1-4e77-a465-70d1ac29c2d3"
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8060, 90, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHCF2euynX6K"
      },
      "source": [
        "# Add classifcation token to beginning of input\n",
        "# classifcation token is an array of 0's and will be the input to the downstream classification tasks\n",
        "\n",
        "def add_cls_token(X):\n",
        "  cls_array = np.zeros((X.shape[0], 1, N_rois))\n",
        "  t_X = np.append(cls_array, X, 1)\n",
        "  return t_X\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqLl3n80oxaY"
      },
      "source": [
        "train_X_t = add_cls_token(train_X) \n",
        "val_X_t = add_cls_token(val_X) \n",
        "test_X_t = add_cls_token(test_X) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMND8g_Lq7wk"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzI3FNQb2zTg",
        "outputId": "fa8e411d-edee-41e9-ec11-c89e2d7845d1"
      },
      "source": [
        "embed_dim = N_rois  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "max_len = L + 1 # add one for the cls token\n",
        "dropout_rate = .5\n",
        "\n",
        "# inputs = layers.Input(shape=(max_len,))\n",
        "inputs = layers.Input(shape=(max_len, embed_dim))\n",
        "# embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "# x = embedding_layer(inputs)\n",
        "x = inputs\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = x[:, 0, :]\n",
        "# x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 91, 200)]         0         \n",
            "_________________________________________________________________\n",
            "transformer_block (Transform (None, 91, 200)           656432    \n",
            "_________________________________________________________________\n",
            "tf.__operators__.getitem (Sl (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                4020      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 660,473\n",
            "Trainable params: 660,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVdgNkrb27QQ",
        "outputId": "3fc5a8d9-97a8-443a-bda3-77e4adeb47c5"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)\n",
        "model.fit(train_X_t, train_Y, batch_size=batch_size, epochs=epochs, validation_data=(val_X_t, val_Y), callbacks=[es_callback])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "252/252 [==============================] - 4s 13ms/step - loss: 0.8042 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6939 - accuracy: 0.5012 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6933 - accuracy: 0.5057 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6934 - accuracy: 0.5101 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6928 - accuracy: 0.5106 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6929 - accuracy: 0.4959 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6925 - accuracy: 0.5027 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6927 - accuracy: 0.5071 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6922 - accuracy: 0.5043 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6927 - accuracy: 0.4969 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6918 - accuracy: 0.4955 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6926 - accuracy: 0.4964 - val_loss: 0.6929 - val_accuracy: 0.5106\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6919 - accuracy: 0.5092 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6927 - accuracy: 0.5177 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6926 - accuracy: 0.5028 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.6923 - accuracy: 0.5139 - val_loss: 0.6930 - val_accuracy: 0.5106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f46c6033210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ6-e4sN3Pam",
        "outputId": "372919c0-47c6-4791-d87a-74c179ffbce6"
      },
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(train_X_t, train_Y, verbose=0)\n",
        "_, test_acc = model.evaluate(test_X_t, test_Y, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.506, Test: 0.562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyWdwtzMpasg"
      },
      "source": [
        "Train: 0.972, Test: 0.645"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkPWW5gvq69f"
      },
      "source": [
        "Transfomer with positional encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXxJUIWQq-dM"
      },
      "source": [
        "class PositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, embed_dim):\n",
        "        super(PositionEmbedding, self).__init__()\n",
        "        self.maxlen = maxlen\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        positions = tf.range(start=0, limit=self.maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ydMbQ3zrqoe",
        "outputId": "c68dc501-7706-4ba4-9eb5-1fd9006c321f"
      },
      "source": [
        "embed_dim = N_rois  # Embedding size for each token\n",
        "num_heads = 8  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "max_len = L + 1\n",
        "dropout_rate = .5\n",
        "\n",
        "# inputs = layers.Input(shape=(max_len,))\n",
        "inputs = layers.Input(shape=(max_len, embed_dim))\n",
        "pos_embedding_layer = PositionEmbedding(max_len, embed_dim)\n",
        "x = pos_embedding_layer(inputs)\n",
        "# x = inputs\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = x[:, 0, :] # take only cls token\n",
        "# x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(dropout_rate)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_embed = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model_embed.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_embed.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 91, 200)]         0         \n",
            "_________________________________________________________________\n",
            "position_embedding (Position (None, 91, 200)           18200     \n",
            "_________________________________________________________________\n",
            "transformer_block (Transform (None, 91, 200)           1298832   \n",
            "_________________________________________________________________\n",
            "tf.__operators__.getitem (Sl (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                4020      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 1,321,073\n",
            "Trainable params: 1,321,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3qmtqUGsAUg",
        "outputId": "79aa0cc0-d56c-4447-8b18-7fd469dbf760"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)\n",
        "history = model_embed.fit(train_X_t, train_Y, batch_size=batch_size, epochs=epochs, validation_data=(val_X_t, val_Y), callbacks=[es_callback])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "252/252 [==============================] - 10s 21ms/step - loss: 0.7237 - accuracy: 0.5264 - val_loss: 0.6944 - val_accuracy: 0.4255\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.6939 - accuracy: 0.5024 - val_loss: 0.7024 - val_accuracy: 0.4255\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.6939 - accuracy: 0.5114 - val_loss: 0.6960 - val_accuracy: 0.4255\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.6933 - accuracy: 0.5139 - val_loss: 0.6956 - val_accuracy: 0.4255\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.6934 - accuracy: 0.5012 - val_loss: 0.6957 - val_accuracy: 0.4255\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.6917 - accuracy: 0.5118 - val_loss: 0.6939 - val_accuracy: 0.4255\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.6841 - accuracy: 0.5267 - val_loss: 0.6782 - val_accuracy: 0.5468\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.6207 - accuracy: 0.6537 - val_loss: 0.6449 - val_accuracy: 0.6362\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.5055 - accuracy: 0.7612 - val_loss: 0.5772 - val_accuracy: 0.7404\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.4571 - accuracy: 0.7962 - val_loss: 0.8198 - val_accuracy: 0.6362\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.3714 - accuracy: 0.8366 - val_loss: 1.0251 - val_accuracy: 0.6511\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.3377 - accuracy: 0.8647 - val_loss: 1.1427 - val_accuracy: 0.6191\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.3258 - accuracy: 0.8677 - val_loss: 1.3800 - val_accuracy: 0.6106\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.2517 - accuracy: 0.9023 - val_loss: 1.3878 - val_accuracy: 0.6383\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.2461 - accuracy: 0.8995 - val_loss: 1.1606 - val_accuracy: 0.6787\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.1924 - accuracy: 0.9269 - val_loss: 1.6337 - val_accuracy: 0.6255\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.2113 - accuracy: 0.9221 - val_loss: 1.4354 - val_accuracy: 0.6447\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.1798 - accuracy: 0.9354 - val_loss: 1.5538 - val_accuracy: 0.6021\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.1679 - accuracy: 0.9381 - val_loss: 1.5083 - val_accuracy: 0.6745\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.1563 - accuracy: 0.9458 - val_loss: 1.2480 - val_accuracy: 0.6638\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.1414 - accuracy: 0.9570 - val_loss: 1.6221 - val_accuracy: 0.6617\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.1154 - accuracy: 0.9592 - val_loss: 0.8799 - val_accuracy: 0.6511\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.1667 - accuracy: 0.9385 - val_loss: 1.3101 - val_accuracy: 0.6553\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.1277 - accuracy: 0.9625 - val_loss: 1.7175 - val_accuracy: 0.6383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB1wWt_isGqP",
        "outputId": "0fdbda82-3ac5-4725-a82e-b4bef64d0369"
      },
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model_embed.evaluate(train_X_t, train_Y, verbose=0)\n",
        "_, test_acc = model_embed.evaluate(test_X_t, test_Y, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.974, Test: 0.584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XFQa28Yy_ykA",
        "outputId": "83b1855e-938d-4bed-cda7-fe0cf2f794a5"
      },
      "source": [
        "def plt_training(var, skip=0, exp_name=None):\n",
        "  plt.plot(history.history[var][skip:])\n",
        "  plt.plot(history.history['val_' + var][skip:])\n",
        "  plt.title('model ' + var)\n",
        "  plt.ylabel(var)\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  if exp_name is not None:\n",
        "    plt.savefig(f'{exp_name}_{var}.png')\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "exp_name = 'L90_8_32_pure'\n",
        "vars = ['loss', 'accuracy']\n",
        "skip = 1\n",
        "plt_training(vars[1], skip, exp_name)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnkNiec5lfnB"
      },
      "source": [
        "def pause():\n",
        "  for i in range(1000230413254123041230421341234):\n",
        "    if i %12132423423141324 == 0:\n",
        "      print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU_GB6x9lkKl",
        "outputId": "bbdcb7ce-0d3b-414f-fdf6-4fa3f17fd1b9"
      },
      "source": [
        "pause()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XRwXCqdlk04"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}